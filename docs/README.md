# Proyecto Final Big Data - Airflow + Kafka + Dask + SQL + ML

Este proyecto demuestra un flujo de procesamiento de datos usando herramientas de Big Data. EstÃ¡ orquestado con **Apache Airflow**, y combina **Kafka, Dask, PostgreSQL/MySQL, Matplotlib y Scikit-learn**.


# ğŸ“ Estructura del Proyecto

```
airflow/
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ proyecto_bigdata_dag.py       # Archivo principal del DAG que orquesta el flujo
â”‚   â”œâ”€â”€ _pycache_                     # Guarda versiones compiladas de los scripts
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ dag_id=proyecto_bigdata       # Logs del DAG ejecutado
â”‚   â”œâ”€â”€ dag_processor_manager         # Logs de Airflow
â”‚   â”œâ”€â”€ scheduler                     # Logs del programador de tareas
â”œâ”€â”€ docs/                            
â”‚   â”œâ”€â”€ README                        # Este archivo, que describe que contiene el proyecto y que hace cada cosa
â”‚   â”œâ”€â”€ ReseÃ±a                        # ReseÃ±a de flujo de procesamiento de datos
â”‚   â”œâ”€â”€ Taller final de Big Data
â”‚   â”œâ”€â”€ Notas
â”œâ”€â”€ scripts/                          # Carpeta auxiliar
â”‚   â”œâ”€â”€ guardar_en_sql.py             # Carga y guarda los datos transformados en SQL
â”‚   â”œâ”€â”€ hacer_grafica.py              # Crea una grÃ¡fica desde los datos
â”‚   â”œâ”€â”€ kafka_ingest.py               # Simula la ingesta de datos con Kafka
â”‚   â”œâ”€â”€ modelo_ml.py                  # Entrena un modelo de machine learning
â”‚   â”œâ”€â”€ transformar_datos.py          # Prcoesa, limpiando y transformando los datos
â”‚    salidas/ 
â”‚   â”œâ”€â”€ datos_leidos.csv
â”‚   â”œâ”€â”€ datos_procesados.csv
â”‚   â”œâ”€â”€ predicciones.csv
â”‚   â”œâ”€â”€ predicciones_futuras.csv
â”‚   â”œâ”€â”€ predicciones_ml.csv
â”‚   â”œâ”€â”€ grafico.png
â”‚   â”œâ”€â”€ grafico_histograma.png
â”‚   â”œâ”€â”€ grafico_histograma.png
â”‚   â”œâ”€â”€ grafico_histograma.png
â”‚   â”œâ”€â”€ grafico_prediccion_futura.png
â”‚   â”œâ”€â”€ modelo_ml.png
â”‚   â”œâ”€â”€ modelo_entrenado.pkl 
â”‚   docker-compose.yml
â”‚   .env
â”‚   descargaDhime.csv
â”‚   docker-compose.yml
â”‚   Dockerfile
â”‚   schema
```
---

# Â¿QuÃ© hace cada script?

- `kafka_ingest.py`: Simula la ingesta de datos desde Kafka (puede leer un archivo CSV o generar datos).
- `transformar_datos.py`: Realiza limpieza, filtrado o transformaciÃ³n de los datos crudos.
- `guardar_en_sql.py`: Inserta los datos en una base de datos SQL (como MySQL o PostgreSQL).
- `hacer_grafica.py`: Genera una grÃ¡fica (PNG) para visualizar los datos procesados.
- `modelo_ml.py`: Entrena un modelo de machine learning (regresiÃ³n o clasificaciÃ³n).
- `airflowdagsproyecto_bigdata_dag.py`: Ejemplo de prueba inicial del DAG.
---

# CÃ³mo ejecutar Airflow

1. Abrir terminal como windows PowerShell y activa entorno virtual.
2. Iniciar la base de datos de Airflow:

```bash
airflow db init
```
3. CreaciÃ³n de un usuario administrador:

```bash
airflow users create \
  --username admin \
  --firstname Johanna \
  --lastname Soler \
  --role Admin \
  --email johannasolermine@gmail.com
```
4. Iniciar los servicios de Airflow:

```bash
airflow scheduler
# En otra terminal:
airflow webserver
```
5. Abrir el navegador y visitar: [http://localhost:8080](http://localhost:8080)
---
# Â¿QuÃ© hace cada tarea del DAG?

El archivo `proyecto_bigdata_dag.py` contiene un DAG con las siguientes tareas:

| Task ID                   | DescripciÃ³n                                                                 |
|---------------------------|-----------------------------------------------------------------------------|
| `leer_kafka`              | Simula la ingesta de datos desde archivo CSV (como si viniera de Kafka).   |
| `procesar_datos_dask`     | Usa Dask para procesar los datos leÃ­dos.                                   |
| `guardar_postgresql`      | Guarda los datos transformados en PostgreSQL.                              |
| `crear_grafico_linea`     | Genera grÃ¡fico de lÃ­nea con Matplotlib.                                    |
| `crear_grafico_outliers`  | DetecciÃ³n visual de valores extremos.                                      |
| `crear_histograma`        | Histograma de frecuencias para la variable.                                |
| `modelo_machine_learning` | Entrena modelo de regresiÃ³n lineal.                                        |
| `entrenar_modelo_ml`      | Script separado para guardar modelo (`pkl`) y predicciones.                |
| `prediccion_futuro`       | Predice valores futuros y genera grÃ¡fica y CSV de resultados.              |

---

# Requisitos

- Docker
- Python 3.10
- Apache Airflow 2.8.1
- Kafka
- Dask
- pandas, matplotlib, scikit-learn
- PostgreSQL

---

# Resultado esperado

Al ejecutar el DAG desde la interfaz de Airflow:

1. Se ingesta, procesa y guarda un dataset simulado de precipitaciones
2. Se visualiza mediante tres tipos de grÃ¡ficas
3. Se entrena un modelo de ML
4. Se hacen predicciones sobre los prÃ³ximos meses
5. Se guardan los resultados en .csv y .png

---